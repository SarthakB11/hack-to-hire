{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "56f33b26",
      "metadata": {
        "id": "56f33b26"
      },
      "source": [
        "# Question Answering with T5 on Quora Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "404031b0",
      "metadata": {
        "id": "404031b0"
      },
      "source": [
        "\n",
        "This notebook demonstrates how to fine-tune and evaluate a T5 model on the Quora Question Answer dataset.\n",
        "We will preprocess the data, fine-tune the model, and evaluate its performance using accuracy and F1-score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a915af36",
      "metadata": {
        "id": "a915af36"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e5e357",
      "metadata": {
        "id": "70e5e357"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e4ed47",
      "metadata": {
        "id": "a5e4ed47"
      },
      "source": [
        "## Device Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45b68e3",
      "metadata": {
        "id": "a45b68e3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Device setup (TPU/GPU/CPU)\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    print('Using TPU')\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    device = xm.xla_device()\n",
        "elif torch.cuda.is_available():\n",
        "    print('Using GPU')\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print('Using CPU')\n",
        "    device = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b0b9eb",
      "metadata": {
        "id": "f8b0b9eb"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9eb880",
      "metadata": {
        "id": "ee9eb880"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"toughdata/quora-question-answer-dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f160c1f",
      "metadata": {
        "id": "3f160c1f"
      },
      "source": [
        "## Load Tokenizer and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84be96d4",
      "metadata": {
        "id": "84be96d4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "142deeb7",
      "metadata": {
        "id": "142deeb7"
      },
      "source": [
        "## Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a414e5",
      "metadata": {
        "id": "41a414e5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare the dataset\n",
        "def preprocess_function(examples):\n",
        "    inputs = [f\"question: {q.strip()}  context: {a}\" for q, a in zip(examples[\"question\"], examples[\"answer\"])]\n",
        "    targets = examples[\"answer\"]\n",
        "\n",
        "    # Tokenize inputs and targets\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Process the entire dataset\n",
        "print(\"Processing dataset...\")\n",
        "processed_dataset = dataset['train'].map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e15d781",
      "metadata": {
        "id": "8e15d781"
      },
      "source": [
        "## Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20200eb",
      "metadata": {
        "id": "b20200eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Manually split the dataset\n",
        "print(\"Splitting dataset...\")\n",
        "train_data, eval_data = train_test_split(processed_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert splits back to Dataset objects\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "eval_dataset = Dataset.from_dict(eval_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d371cf5",
      "metadata": {
        "id": "0d371cf5"
      },
      "source": [
        "## Select Subset for Training (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "277740b6",
      "metadata": {
        "id": "277740b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Use a smaller subset for faster training\n",
        "print(\"Selecting subset for training...\")\n",
        "train_dataset = train_dataset.shuffle(seed=42).select(range(5000))\n",
        "eval_dataset = eval_dataset.shuffle(seed=42).select(range(500))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f50e2bf4",
      "metadata": {
        "id": "f50e2bf4"
      },
      "source": [
        "## Define Metric Computation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7f201d",
      "metadata": {
        "id": "bd7f201d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define metric computation function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    # Convert logits to predictions\n",
        "    decoded_preds = tokenizer.batch_decode(logits, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Compute metrics (using accuracy and F1 for simplicity)\n",
        "    accuracy = accuracy_score(decoded_labels, decoded_preds)\n",
        "    f1 = f1_score(decoded_labels, decoded_preds, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a4ce29",
      "metadata": {
        "id": "d1a4ce29"
      },
      "source": [
        "## Set Up the Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd18fa08",
      "metadata": {
        "id": "dd18fa08"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set up the trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    tpu_num_cores=8 if 'COLAB_TPU_ADDR' in os.environ else None,\n",
        "    tf32=True if 'COLAB_TPU_ADDR' in os.environ else False,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45640112",
      "metadata": {
        "id": "45640112"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6970424",
      "metadata": {
        "id": "f6970424"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ea7dd8a",
      "metadata": {
        "id": "5ea7dd8a"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "667562fe",
      "metadata": {
        "id": "667562fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating model...\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", eval_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy- 90.56%\n",
        "\n",
        " ROUGE-1: 0.88\n",
        "\n",
        " BLEU: 0.80\n",
        "\n",
        " F1-score: 0.83"
      ],
      "metadata": {
        "id": "EcklQUsBvCe6"
      },
      "id": "EcklQUsBvCe6"
    },
    {
      "cell_type": "markdown",
      "id": "88f40fc1",
      "metadata": {
        "id": "88f40fc1"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f56133b",
      "metadata": {
        "id": "6f56133b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./quora_qa_t5_model\")\n",
        "tokenizer.save_pretrained(\"./quora_qa_t5_tokenizer\")\n",
        "print(\"Model and tokenizer saved.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}